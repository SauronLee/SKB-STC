{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82613c29",
   "metadata": {},
   "source": [
    "# GNN for NLP\n",
    "* STC-SKB-GRAPH-Ohsumed\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0b62ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/adaptsystemlab2019/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/adaptsystemlab2019/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/adaptsystemlab2019/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f91f93f",
   "metadata": {},
   "source": [
    "# Short Text Classification (STC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8385537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "STC_Benchmark_path = \"../benchmark\"\n",
    "Ohsumed_training: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_training.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_test: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_test.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_category_description: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_category_description.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_ohsumed_all: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_ohsumed_all.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19de273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ohsumed_ohsumed_all_tagme: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_ohsumed_all_tagme.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_training_tagme: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_training_tagme.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_test_tagme: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_test_tagme.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_category_description_tagme: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_category_description_tagme.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e14d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagmeProcess(tagme_json):\n",
    "    tagme_dict = {}\n",
    "    for items in tqdm.tqdm(tagme_json):\n",
    "        if not items:\n",
    "            continue \n",
    "        i, entityList = items.split(\"\\t\")\n",
    "        if entityList == \"null\" or len(entityList) == 0:\n",
    "            continue\n",
    "        entityList = json.loads(entityList)\n",
    "        entities_spot = [d['spot'] for d in entityList if 'title' in d and float(d['rho']) > 0.1]\n",
    "        entities_title = [d['title'] for d in entityList if 'title' in d and float(d['rho']) > 0.1]\n",
    "        entities = (entities_spot,entities_title)\n",
    "        if i not in tagme_dict.keys():\n",
    "            tagme_dict[i] = []\n",
    "        tagme_dict[i] = entities\n",
    "    return tagme_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a29c63f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 18292/18292 [00:00<00:00, 69143.77it/s]\n",
      "100%|████████████████████████████████████| 3357/3357 [00:00<00:00, 74003.90it/s]\n",
      "100%|████████████████████████████████████| 4043/4043 [00:00<00:00, 68717.84it/s]\n"
     ]
    }
   ],
   "source": [
    "Ohsumed_ohsumed_all_tagme = tagmeProcess(Ohsumed_ohsumed_all_tagme)\n",
    "Ohsumed_training_tagme = tagmeProcess(Ohsumed_training_tagme)\n",
    "Ohsumed_test_tagme = tagmeProcess(Ohsumed_test_tagme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf51a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9846380931554775\n",
      "4.867441167709265\n",
      "4.9121939154093495\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(t) for (_,t) in Ohsumed_ohsumed_all_tagme.values()])/len(Ohsumed_ohsumed_all))\n",
    "print(sum([len(t) for (_,t) in Ohsumed_training_tagme.values()])/len(Ohsumed_training))\n",
    "print(sum([len(t) for (_,t) in Ohsumed_test_tagme.values()])/len(Ohsumed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1e0922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.106986660835338\n",
      "11.820971105153411\n",
      "12.016077170418006\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(c.split(\" \")) for c in Ohsumed_ohsumed_all.keys()])/len(Ohsumed_ohsumed_all))\n",
    "print(sum([len(c.split(\" \")) for c in Ohsumed_training.keys()])/len(Ohsumed_training))\n",
    "print(sum([len(c.split(\" \")) for c in Ohsumed_test.keys()])/len(Ohsumed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ba47a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clostridium difficile invasion and toxin circulation in fatal pediatric pseudomembranous colitis.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Ohsumed_training.keys())[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be634efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Clostridium difficile',\n",
       "  'invasion',\n",
       "  'toxin',\n",
       "  'circulation',\n",
       "  'fatal',\n",
       "  'pediatric',\n",
       "  'pseudomembranous colitis'],\n",
       " ['Clostridium difficile (bacteria)',\n",
       "  'Invasive species',\n",
       "  'Toxin',\n",
       "  'Circulatory system',\n",
       "  'Death',\n",
       "  'Pediatrics',\n",
       "  'Clostridium difficile colitis'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Ohsumed_training_tagme.values())[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a8dc2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def lemmatization(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_sent = pos_tag(tokens)\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmas_sent = []\n",
    "    for tag in tagged_sent:\n",
    "        wordnet_pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n",
    "        lemmas_sent.append((wnl.lemmatize(tag[0], pos = wordnet_pos),wordnet_pos))\n",
    "    return lemmas_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33c08179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Intraocular', 'a'),\n",
       " ('pressure', 'n'),\n",
       " ('change', 'n'),\n",
       " ('and', 'n'),\n",
       " ('postural', 'a'),\n",
       " ('change', 'n'),\n",
       " ('of', 'n'),\n",
       " ('intraocular', 'a'),\n",
       " ('pressure', 'n'),\n",
       " ('in', 'n'),\n",
       " ('experimentally', 'r'),\n",
       " ('induced', 'a'),\n",
       " ('Hansen', 'n'),\n",
       " (\"'s\", 'n'),\n",
       " ('disease', 'n'),\n",
       " ('of', 'n'),\n",
       " ('rhesus', 'n'),\n",
       " (',', 'n'),\n",
       " ('mangabey', 'n'),\n",
       " (',', 'n'),\n",
       " ('and', 'n'),\n",
       " ('African', 'n'),\n",
       " ('green', 'a'),\n",
       " ('monkey', 'n'),\n",
       " ('.', 'n')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatization(list(Ohsumed_training.keys())[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e85e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictskb_dict = np.load(\"../sememe_dataset/DictSKB_dict.npy\", allow_pickle=True).tolist()\n",
    "dictskb_sememes = np.load(\"../sememe_dataset/DictSKB_sememes.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f36a0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "skb_ad_dict = np.load(\"../sememe_dataset/skb_ad_dict.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a3ad1fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', {'monkey', 'tribe'}),\n",
       " ('n', {'arboreal', 'eyelid', 'limb', 'monkey', 'tail', 'white'})]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb_ad_dict['mangabey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6fa83fd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mangabey'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20471/462959669.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdictskb_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mangabey'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'mangabey'"
     ]
    }
   ],
   "source": [
    "dictskb_dict['mangabey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1004745e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
