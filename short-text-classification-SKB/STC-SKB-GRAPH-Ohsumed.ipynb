{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82613c29",
   "metadata": {},
   "source": [
    "# GNN for NLP\n",
    "* STC-SKB-GRAPH-Ohsumed\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b62ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/adaptsystemlab2019/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/adaptsystemlab2019/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/adaptsystemlab2019/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f91f93f",
   "metadata": {},
   "source": [
    "# Short Text Classification (STC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8385537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "STC_Benchmark_path = \"../benchmark\"\n",
    "Ohsumed_training: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_training.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_test: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_test.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_category_description: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_category_description.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_ohsumed_all: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_ohsumed_all.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19de273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ohsumed_ohsumed_all_tagme: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_ohsumed_all_tagme.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_training_tagme: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_training_tagme.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_test_tagme: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_test_tagme.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_category_description_tagme: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_category_description_tagme.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e14d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagmeProcess(tagme_json):\n",
    "    tagme_dict = {}\n",
    "    for items in tqdm.tqdm(tagme_json):\n",
    "        if not items:\n",
    "            continue \n",
    "        i, entityList = items.split(\"\\t\")\n",
    "        if entityList == \"null\" or len(entityList) == 0:\n",
    "            continue\n",
    "        entityList = json.loads(entityList)\n",
    "        entities_spot = [d['spot'] for d in entityList if 'title' in d and float(d['rho']) > 0.1]\n",
    "        entities_title = [d['title'] for d in entityList if 'title' in d and float(d['rho']) > 0.1]\n",
    "        entities = (entities_spot,entities_title)\n",
    "        if i not in tagme_dict.keys():\n",
    "            tagme_dict[i] = []\n",
    "        tagme_dict[i] = entities\n",
    "    return tagme_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a29c63f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 18292/18292 [00:00<00:00, 65143.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 3357/3357 [00:00<00:00, 74999.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 4043/4043 [00:00<00:00, 73314.19it/s]\n"
     ]
    }
   ],
   "source": [
    "Ohsumed_ohsumed_all_tagme = tagmeProcess(Ohsumed_ohsumed_all_tagme)\n",
    "Ohsumed_training_tagme = tagmeProcess(Ohsumed_training_tagme)\n",
    "Ohsumed_test_tagme = tagmeProcess(Ohsumed_test_tagme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf51a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9846380931554775\n",
      "4.867441167709265\n",
      "4.9121939154093495\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(t) for (_,t) in Ohsumed_ohsumed_all_tagme.values()])/len(Ohsumed_ohsumed_all))\n",
    "print(sum([len(t) for (_,t) in Ohsumed_training_tagme.values()])/len(Ohsumed_training))\n",
    "print(sum([len(t) for (_,t) in Ohsumed_test_tagme.values()])/len(Ohsumed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e0922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.106986660835338\n",
      "11.820971105153411\n",
      "12.016077170418006\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(c.split(\" \")) for c in Ohsumed_ohsumed_all.keys()])/len(Ohsumed_ohsumed_all))\n",
    "print(sum([len(c.split(\" \")) for c in Ohsumed_training.keys()])/len(Ohsumed_training))\n",
    "print(sum([len(c.split(\" \")) for c in Ohsumed_test.keys()])/len(Ohsumed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba47a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(Ohsumed_training.keys())[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be634efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(Ohsumed_training_tagme.values())[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8dc2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def lemmatization(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_sent = pos_tag(tokens)\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmas_sent = []\n",
    "    for tag in tagged_sent:\n",
    "        wordnet_pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n",
    "        lemmas_sent.append((wnl.lemmatize(tag[0], pos = wordnet_pos),wordnet_pos))\n",
    "    return lemmas_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9c5b9",
   "metadata": {},
   "source": [
    "## Analysis for OOV on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "457ef6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordFreq(docs):\n",
    "    word_freq = {}\n",
    "    for doc in docs:\n",
    "        for word in doc.split():\n",
    "            if word in word_freq:\n",
    "                word_freq[word] += 1\n",
    "            else:\n",
    "                word_freq[word] = 1\n",
    "    return word_freq\n",
    "def evaluationFrequncy(docs,save_name,limit_num):\n",
    "    '''evaluation frequncy for document lexions'''\n",
    "    word_freq = wordFreq(docs)\n",
    "    print(\"=======analysis start=======\")\n",
    "    print(\"#all word size: \", len(word_freq))\n",
    "    limit_word_freq_len = len([v for k,v in word_freq.items() if v < limit_num])\n",
    "    word_freq_sorted = sorted(word_freq.items(), key = lambda kv:(kv[1], kv[0]))\n",
    "    print(\"#frequncy < \"+ str(limit_num) +\": \", limit_word_freq_len)\n",
    "    print(\"#frequncy mean: \", np.mean(list(word_freq.values())))\n",
    "    print(\"#frequncy standard deviation: \", np.std(list(word_freq.values())))\n",
    "    print(\"#frequncy std/mean: \", np.std(list(word_freq.values()))/np.mean(list(word_freq.values())))\n",
    "    #axes = sns.scatterplot(data=list(word_freq.values())).set_title(save_name)\n",
    "    #axes.figure.set_size_inches(18,4)\n",
    "    #fig = axes.get_figure()\n",
    "    #fig.savefig(\"../data/images/\"+save_name+\".png\", dpi = 400)\n",
    "    return word_freq, word_freq_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35ef04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ohsumed = dict(Ohsumed_test,**Ohsumed_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3f40ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ohsumed_list = [k for k,v in Ohsumed_test.items()] + [k for k,v in Ohsumed_training.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d370f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Ohsumed_stc_list\",Ohsumed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e074e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======analysis start=======\n",
      "#all word size:  18346\n",
      "#frequncy < 5:  15710\n",
      "#frequncy mean:  4.809331734438024\n",
      "#frequncy standard deviation:  65.32569453623601\n",
      "#frequncy std/mean:  13.58311261177108\n"
     ]
    }
   ],
   "source": [
    "raw_word_freq, raw_word_freq_sorted = evaluationFrequncy(Ohsumed_list,\"raw_ohsumed\",limit_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b573be",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_content_tuple = (raw_word_freq,raw_word_freq_sorted,Ohsumed_list)\n",
    "np.save(\"../data/corpus/Ohsumed_stc_tuple\", doc_content_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0dee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ohsumed_ohsumed_all_tagme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c5e41",
   "metadata": {},
   "source": [
    "## Get the DictSKB and own SKB-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e85e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictskb_dict = np.load(\"../sememe_dataset/DictSKB_dict.npy\", allow_pickle=True).tolist()\n",
    "dictskb_sememes = np.load(\"../sememe_dataset/DictSKB_sememes.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f36a0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "skb_ad_dict = np.load(\"../sememe_dataset/skb_ad_dict.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f1330ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The national immunization program of The Netherlands.', ['C01'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Ohsumed_training.items())[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb91db41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('verb', {'protect'})]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictskb_dict[\"immunization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c9ad4d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', {'agent', 'immune', 'infectious', 'process'}), ('n', {'immune'})]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb_ad_dict[\"immunization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429a82e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
