{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d7a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json, os\n",
    "from nltk.corpus import wordnet as wn\n",
    "from math import log\n",
    "import glob\n",
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264bfcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getTextFile(langual):\n",
    "    file_list = glob.glob(f'../data/stopwords/stopwords/*_{langual}.txt')\n",
    "    files = \",\".join(file_list)\n",
    "    return files\n",
    "def countMinMaxAver(lines):\n",
    "    min_len = 10000\n",
    "    aver_len = 0\n",
    "    max_len = 0\n",
    "    for temp in lines:\n",
    "        aver_len = aver_len + len(temp)\n",
    "        if len(temp) < min_len:\n",
    "            min_len = len(temp)\n",
    "        if len(temp) > max_len:\n",
    "            max_len = len(temp)\n",
    "    aver_len = 1.0 * aver_len / len(lines)\n",
    "    print('min_len : ' + str(min_len))\n",
    "    print('max_len : ' + str(max_len))\n",
    "    print('average_len : ' + str(aver_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb805a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set()\n",
    "for file in _getTextFile(\"en\").split(\",\"):\n",
    "    for word in open(file):\n",
    "        stop_words.add(word.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beac6279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sememe_entity_sence = np.load(\"../data/sememe_entity_sence.npy\", allow_pickle=True).tolist()\n",
    "#title_content_lemmatization_sence = np.load(\"../data/title_content_lemmatization_sence.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50603ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_list = list(title_content_lemmatization_sence.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "641fc543",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdv = np.load(\"./data/wordnet_voc.npy\", allow_pickle=True).tolist()\n",
    "tagme_sememe_dict_l = np.load(\"./data/wiki_lem.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5cca597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCov(data):\n",
    "    title_sememe_raw = {}\n",
    "    for k, v in tqdm.tqdm(data.items()):\n",
    "        sememe = []\n",
    "        for w in v:\n",
    "            if w in cdv:\n",
    "            #if w in dict_sememes:\n",
    "                sememe.append(w)\n",
    "        if len(sememe) == 0:\n",
    "            continue\n",
    "        title_sememe_raw[k] = sememe\n",
    "\n",
    "    print(\"take max [:5000] in content lexion for sememe (raw)\")\n",
    "    countMinMaxAver(title_sememe_raw)\n",
    "    return title_sememe_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "493b5748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 6329832/6329832 [1:19:22<00:00, 1329.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take max [:5000] in content lexion for sememe (raw)\n",
      "min_len : 1\n",
      "max_len : 211\n",
      "average_len : 19.87859688069617\n"
     ]
    }
   ],
   "source": [
    "tagme_sememe_dict_l = getCov(tagme_sememe_dict_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e70d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"tagme_sememe_dict_l\",tagme_sememe_dict_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b28c51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansememes(tagme_sememe_dict_l):\n",
    "    sememe_skb = {}\n",
    "    for k,v in tqdm.tqdm(tagme_sememe_dict_l.items()):\n",
    "        v = set(v)\n",
    "        if w in v:\n",
    "            v.remove(w)\n",
    "        sememe_skb[k] = list(v)\n",
    "    return sememe_skb\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5db54659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 6115403/6115403 [00:18<00:00, 331511.54it/s]\n"
     ]
    }
   ],
   "source": [
    "tagme_sememe_dict_l = cleansememes(tagme_sememe_dict_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5b520966",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagme_sememe_dict_l = {k:v for k,v in tagme_sememe_dict_l.items() if len(v) != 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e50dd402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 6115403/6115403 [00:12<00:00, 502398.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sememe lexion size:  4455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sememe_freq = {}\n",
    "sememe_set = set()\n",
    "for doc_sememes in tqdm.tqdm(tagme_sememe_dict_l.values()):\n",
    "    for sememe in doc_sememes:\n",
    "        sememe_set.add(sememe)\n",
    "        if sememe in sememe_freq:\n",
    "            sememe_freq[sememe] += 1\n",
    "        else:\n",
    "            sememe_freq[sememe] = 1\n",
    "\n",
    "sememe_lexion = list(sememe_set)\n",
    "sememe_lexion_size = len(sememe_lexion)\n",
    "\n",
    "sememe_id_map = {}\n",
    "for i in range(sememe_lexion_size):\n",
    "    sememe_id_map[sememe_lexion[i]] = i\n",
    "\n",
    "print(\"sememe lexion size: \", sememe_lexion_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c660b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6115403it [00:44, 137888.25it/s]\n",
      "6115403it [00:20, 303068.07it/s]\n"
     ]
    }
   ],
   "source": [
    "doc_word_freq = {}\n",
    "for doc_id,(_, doc_words) in tqdm.tqdm(enumerate(tagme_sememe_dict_l.items())):\n",
    "    for word in doc_words:\n",
    "        word_id = sememe_id_map[word]\n",
    "        doc_word_str = str(doc_id) + ',' + str(word_id)\n",
    "        if doc_word_str in doc_word_freq:\n",
    "            doc_word_freq[doc_word_str] += 1\n",
    "        else:\n",
    "            doc_word_freq[doc_word_str] = 1\n",
    "            \n",
    "word_doc_list = {}\n",
    "for i,(_, doc_words) in tqdm.tqdm(enumerate(tagme_sememe_dict_l.items())):\n",
    "    appeared = set()\n",
    "    for word in doc_words:\n",
    "        if word in appeared:\n",
    "            continue\n",
    "        if word in word_doc_list:\n",
    "            doc_list = word_doc_list[word]\n",
    "            doc_list.append(i)\n",
    "            word_doc_list[word] = doc_list\n",
    "        else:\n",
    "            word_doc_list[word] = [i]\n",
    "        appeared.add(word)\n",
    "        \n",
    "word_doc_freq = {}\n",
    "for word, doc_list in word_doc_list.items():\n",
    "    word_doc_freq[word] = len(doc_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3ff59836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6115403it [01:23, 73193.85it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf_word2doc_all = {}\n",
    "for i,(title, doc_words) in tqdm.tqdm(enumerate(tagme_sememe_dict_l.items())):\n",
    "    doc_word_set = set()\n",
    "    for word in doc_words:\n",
    "        if word in doc_word_set or word == title:\n",
    "            continue\n",
    "        j = sememe_id_map[word]\n",
    "        key = str(i) + ',' + str(j)\n",
    "        freq = doc_word_freq[key]\n",
    "        idf = log(1.0 * len(tagme_sememe_dict_l) / word_doc_freq[sememe_lexion[j]])\n",
    "        tfidf_word2doc_all[key] = freq * idf\n",
    "        doc_word_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12365178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0107c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limitSememe(tfidf_word2doc_all,uper,tagme_sememe_dict_l):\n",
    "    sememe_network = {}\n",
    "    for title, sememes in tqdm.tqdm(tagme_sememe_dict_l.items()):\n",
    "        sememes = list(set(sememes))\n",
    "        if len(sememes) != 0:\n",
    "            if len(sememes) > uper:\n",
    "                \n",
    "                title_index,sememe_index = title.split(\",\")\n",
    "                \n",
    "                limitsememes = []\n",
    "                score_list = []\n",
    "                for sememe in sememes:\n",
    "                    score_list.append(tfidf_word2doc_all[str(title_map[title])+\",\"+str(sememe_id_map[sememe])])\n",
    "                if len(score_list) == len(sememes):\n",
    "                    max_index = map(score_list.index, heapq.nlargest(uper,score_list))\n",
    "                    for max_index_i in set(max_index):\n",
    "                        limitsememes.append(sememes[max_index_i])\n",
    "                else:\n",
    "                    print(\"ERROR:\",title,score_list,sememes)\n",
    "                \n",
    "                sememe_network[word] = limitsememes\n",
    "            \n",
    "            else:\n",
    "                sememe_network[word] = sememes\n",
    "        else:\n",
    "            continue\n",
    "    return sememe_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4bc329f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limitSememe(tfidf_word2doc_all,uper,tagme_sememe_dict_l):\n",
    "    sememe_network_index = {}\n",
    "    \n",
    "    for title, score in tqdm.tqdm(tfidf_word2doc_all.items()):\n",
    "        title_index,sememe_index = title.split(\",\")\n",
    "        if title_index not in sememe_network_index.keys():\n",
    "            sememe_network_index[title_index] = []\n",
    "        sememe_network_index[title_index].append((sememe_index,score))\n",
    "        \n",
    "    sememe_network = {}\n",
    "    title_map = {index:title for index, title in enumerate(tagme_sememe_dict_l.keys())}\n",
    "    for k, v in tqdm.tqdm(sememe_network_index.items()):\n",
    "        if len(v) > 10:\n",
    "            score_list = []\n",
    "            sememe_list = []\n",
    "            upper_sememe = []\n",
    "            for (s_i, sc) in v:\n",
    "                score_list.append(sc)\n",
    "                sememe_list.append(sememe_lexion[int(s_i)])\n",
    "            max_index = map(score_list.index, heapq.nlargest(uper,score_list))\n",
    "            for max_index_i in max_index:\n",
    "                upper_sememe.append(sememe_list[max_index_i])\n",
    "            \n",
    "            sememe_network[title_map[int(k)]] = upper_sememe\n",
    "        else:\n",
    "            sememe_list = []\n",
    "            for (s_i, _) in v:\n",
    "                sememe_list.append(sememe_lexion[int(s_i)])\n",
    "            sememe_network[title_map[int(k)]] = sememe_list\n",
    "    return sememe_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "97509903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 54651786/54651786 [00:46<00:00, 1170442.15it/s]\n",
      "100%|█████████████████████████████| 6114239/6114239 [00:32<00:00, 186310.52it/s]\n"
     ]
    }
   ],
   "source": [
    "sememe_network = limitSememe(tfidf_word2doc_all,10,tagme_sememe_dict_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0f4c48d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6114239"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sememe_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c0588e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size:  4455\n"
     ]
    }
   ],
   "source": [
    "word_freq = {}\n",
    "word_set = set()\n",
    "for words in sememe_network.values():\n",
    "    for word in words:\n",
    "        word_set.add(word)\n",
    "        if word in word_freq:\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "\n",
    "vocab = list(word_set)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_id_map = {}\n",
    "for i in range(vocab_size):\n",
    "    word_id_map[vocab[i]] = i\n",
    "\n",
    "print(\"vocab_size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "02a38661",
   "metadata": {},
   "outputs": [],
   "source": [
    "sememe_network = {k:v for k, v in sememe_network.items() if len(v) != 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "353b487c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(sememe_network.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cbe5faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/wiki_skb\",sememe_network)\n",
    "np.save(\"./data/wiki_cdv\",vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8349e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
