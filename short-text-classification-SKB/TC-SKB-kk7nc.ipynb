{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a26d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/adaptsystemlab2019/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/adaptsystemlab2019/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/adaptsystemlab2019/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import tqdm\n",
    "import sys\n",
    "import json\n",
    "import spacy\n",
    "from scipy import linalg, mat, dot, stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "from scipy import linalg, mat, dot, stats\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "dataset = \"ohsumed\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6ff8b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = re.sub(r\"patients \", \"\", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "def load_stopwords(filepath='../stopwords/stopwords_en.txt'):\n",
    "    stopwords = set()\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            swd = line.strip()\n",
    "            stopwords.add(swd)\n",
    "    return stopwords\n",
    "\n",
    "def cleanText(english_txt):\n",
    "    stop_words = load_stopwords()\n",
    "    stop_words.add('')\n",
    "    try:\n",
    "        word_tokens = english_txt.split()\n",
    "        filtered_word = [w for w in word_tokens if w not in stop_words and not w.isdigit()]\n",
    "        filtered_word = [w + \" \" for w in filtered_word]\n",
    "        return \"\".join(filtered_word)\n",
    "    except:\n",
    "        return np.nan\n",
    "def cleanNonEnglish(txt):\n",
    "    txt = clean_str(txt)\n",
    "    txt = re.sub(r'\\W+', ' ', txt)\n",
    "    txt = txt.lower()\n",
    "    txt = txt.replace(\"[^a-zA-Z]\", \" \")\n",
    "    word_tokens = txt.split()\n",
    "    filtered_word = [w for w in word_tokens if all(ord(c) < 128 for c in w)]\n",
    "    filtered_word = [w + \" \" for w in filtered_word]\n",
    "    return \"\".join(filtered_word)\n",
    "\n",
    "def reuptext(text_list):\n",
    "    updata_text_list = []\n",
    "    stop_word=load_stopwords()\n",
    "    stop_word.add('')\n",
    "    for sentence in text_list:\n",
    "        updata_sentence = []\n",
    "        for word in sentence.split(\" \"):\n",
    "            if word not in stop_word:\n",
    "                updata_sentence.append(word)\n",
    "        updata_text_list.append(\" \".join(updata_sentence))\n",
    "    return updata_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1481b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordFreq(docs):\n",
    "    word_freq = {}\n",
    "    for doc in docs:\n",
    "        for word in doc.split():\n",
    "            if word in word_freq:\n",
    "                word_freq[word] += 1\n",
    "            else:\n",
    "                word_freq[word] = 1\n",
    "    return word_freq\n",
    "def evaluationFrequncy(docs,save_name,limit_num):\n",
    "    '''evaluation frequncy for document lexions'''\n",
    "    word_freq = wordFreq(docs)\n",
    "    print(\"=======analysis start=======\")\n",
    "    print(\"#all word size: \", len(word_freq))\n",
    "    limit_word_freq_len = len([v for k,v in word_freq.items() if v < limit_num])\n",
    "    word_freq_sorted = sorted(word_freq.items(), key = lambda kv:(kv[1], kv[0]))\n",
    "    print(\"#frequncy < \"+ str(limit_num) +\": \", limit_word_freq_len)\n",
    "    print(\"#frequncy mean: \", np.mean(list(word_freq.values())))\n",
    "    print(\"#frequncy standard deviation: \", np.std(list(word_freq.values())))\n",
    "    print(\"#frequncy std/mean: \", np.std(list(word_freq.values()))/np.mean(list(word_freq.values())))\n",
    "    #axes = sns.scatterplot(data=list(word_freq.values())).set_title(save_name)\n",
    "    #axes.figure.set_size_inches(18,4)\n",
    "    #fig = axes.get_figure()\n",
    "    #fig.savefig(\"../data/images/\"+save_name+\".png\", dpi = 400)\n",
    "    return word_freq, word_freq_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0686fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSKB(skb):\n",
    "    clean_skb = {}\n",
    "    for word, items in tqdm.tqdm(skb.items()):\n",
    "        if word not in clean_skb.keys():\n",
    "            clean_skb[word] = []\n",
    "        for (pos, sememe_set) in items:\n",
    "            if word in clean_skb.keys() and len(sememe_set) != 0: \n",
    "                clean_skb[word].append((pos, sememe_set))\n",
    "    return clean_skb\n",
    "\n",
    "def removeWikiSenseOnSKBDA(skb_da_dict):\n",
    "    '''uniform for SKB-DA sense'''\n",
    "    skb_da_pure_dict = {}\n",
    "    skb_da_cdv_set = set()\n",
    "    for word, sense in tqdm.tqdm(skb_da_dict.items()):\n",
    "        for (pos, sememe_set) in sense:\n",
    "            if \" (\" in word:\n",
    "                if len(word.split(\" (\")) == 3:\n",
    "                    word, sense1,sense2 = word.split(\" (\")\n",
    "                    sense1 = sense1.replace(\")\",\"\")\n",
    "                    sense2 = sense2.replace(\")\",\"\")\n",
    "                    if word not in skb_da_pure_dict.keys():\n",
    "                        skb_da_pure_dict[word] = []\n",
    "                    #sememe_set.add(sense1)\n",
    "                    #sememe_set.add(sense2)\n",
    "                    sememe_set.discard(word)\n",
    "                    skb_da_pure_dict[word].append((sense1+\" - \"+sense2,sememe_set))\n",
    "                    skb_da_cdv_set =  skb_da_cdv_set | sememe_set\n",
    "                    continue\n",
    "                word, sense = word.split(\" (\")\n",
    "                sense = sense.replace(\")\",\"\")\n",
    "                if word not in skb_da_pure_dict.keys():\n",
    "                    skb_da_pure_dict[word] = []\n",
    "                #sememe_set.add(sense)\n",
    "                sememe_set.discard(word)\n",
    "                skb_da_pure_dict[word].append((sense,sememe_set))\n",
    "                skb_da_cdv_set =  skb_da_cdv_set | sememe_set\n",
    "            else:\n",
    "                if word not in skb_da_pure_dict.keys():\n",
    "                    skb_da_pure_dict[word] = []\n",
    "                sememe_set.discard(word)\n",
    "                skb_da_pure_dict[word].append((pos,sememe_set))\n",
    "                skb_da_cdv_set =  skb_da_cdv_set | sememe_set\n",
    "    print(\"#all lexicon of SKB-DA: {}; #CDV of SKB-DA: {}\".format(len(skb_da_pure_dict),len(skb_da_cdv_set)))\n",
    "    return cleanSKB(skb_da_pure_dict),skb_da_cdv_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9382643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(vec1,vec2):\n",
    "    return vec1.dot(vec2)/(linalg.norm(vec1)*linalg.norm(vec2))\n",
    "    \n",
    "def catSememe(word, sememe_set, embedding_dict, upper_max):\n",
    "    order_embedding_list = []\n",
    "    if word not in embedding_dict.keys():\n",
    "        word = '<unk>'\n",
    "    for sememe in sememe_set:\n",
    "        if sememe in embedding_dict:\n",
    "            order_embedding_list.append(cos(embedding_dict[word],embedding_dict[sememe]))\n",
    "        else:\n",
    "            order_embedding_list.append(cos(embedding_dict[word],embedding_dict['<unk>']))\n",
    "    sememe_set = list(sememe_set)\n",
    "    return set(sememe_set[order_embedding_list.index(v)] for v in sorted(order_embedding_list)[-upper_max:])\n",
    "    \n",
    "def upperMaxSKB(skb_dict, embedding_dict, upper_max):\n",
    "    limit_skb = {}\n",
    "    for word, items in tqdm.tqdm(skb_dict.items()):\n",
    "        if word not in limit_skb.keys():\n",
    "            limit_skb[word] = []\n",
    "        for (pos, sememe_set) in items:\n",
    "            if len(sememe_set) > upper_max:\n",
    "                a = catSememe(word, sememe_set,embedding_dict,upper_max)\n",
    "                limit_skb[word].append((pos, a))\n",
    "                #print(word,a)\n",
    "            else:\n",
    "                limit_skb[word].append((pos, sememe_set))\n",
    "    return limit_skb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b8cf8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    '''Loading Glove Model'''\n",
    "    f = open(gloveFile,'r', encoding='utf8')\n",
    "    model = {}\n",
    "    for line in tqdm.tqdm(f):\n",
    "        splitLine = line.split(' ')\n",
    "        word = splitLine[0]\n",
    "        embedding = np.asarray(splitLine[1:], dtype='float32')\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6d75c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CosineSimilarity(x1, x2):\n",
    "    x2 = x2.t()\n",
    "    x = x1.mm(x2)\n",
    "    x1_frobenius = x1.norm(dim=1).unsqueeze(0).t()\n",
    "    x2_frobenins = x2.norm(dim=0).unsqueeze(0)\n",
    "    x_frobenins = x1_frobenius.mm(x2_frobenins)\n",
    "    final = x.mul(1/x_frobenins)\n",
    "    return final\n",
    "def localAttention(sentence_str, word_str, sememe_list, embedding_dict):\n",
    "    '''\n",
    "        input: sentence_str, word_str, embedding_dict\n",
    "        oytput: word embedding\n",
    "    '''\n",
    "    #print(sentence_str, word_str)\n",
    "    context_embedding_list = []\n",
    "    sentence_list = sentence_str.split()\n",
    "    if sentence_str != word_str:\n",
    "        sentence_list.remove(word_str)\n",
    "    for word in sentence_list:\n",
    "        if word in embedding_dict.keys():\n",
    "            context_embedding_list.append(embedding_dict[word])\n",
    "        else:\n",
    "            context_embedding_list.append(embedding_dict['<unk>'])\n",
    "\n",
    "    context_embedding_list = torch.Tensor(context_embedding_list).to(device)\n",
    "    word_embedding = torch.from_numpy(embedding_dict[word_str]).float().unsqueeze(0).to(device)\n",
    "    #print(context_embedding_list.size(),word_embedding.size())\n",
    "    cos_value_w = CosineSimilarity(context_embedding_list, word_embedding).to(device)\n",
    "    softmax_nn = nn.Softmax(dim=0)\n",
    "    softmax_weight_w = softmax_nn(cos_value_w) * 4\n",
    "    '''\n",
    "        get local word embedding\n",
    "    '''\n",
    "    local_word_embedding = softmax_weight_w.t().mm(context_embedding_list)\n",
    "    \n",
    "    \n",
    "    sememes_embedding_list = []\n",
    "    for sememe in sememe_list:\n",
    "        if sememe in embedding_dict.keys():\n",
    "            sememes_embedding_list.append(embedding_dict[sememe])\n",
    "        else:\n",
    "            sememes_embedding_list.append(embedding_dict['<unk>'])\n",
    "            \n",
    "    sememes_embedding_list = torch.Tensor(sememes_embedding_list).to(device)\n",
    "    cos_value_s = CosineSimilarity(sememes_embedding_list, local_word_embedding).to(device)\n",
    "    softmax_weight_s = softmax_nn(cos_value_s) * 2\n",
    "    local_sememe_embedding = softmax_weight_s.t().mm(sememes_embedding_list)\n",
    "    cos_value = CosineSimilarity(local_sememe_embedding,local_word_embedding)\n",
    "    \n",
    "    return cos_value.to('cpu').squeeze(0).numpy().tolist()\n",
    "\n",
    "def replaceWord2Sememe(embedding_dict, skb_dict, docs_tuple,threshold,skb_cdv_map,ferquncy_max):\n",
    "    '''\n",
    "        input: \n",
    "        process: if the word of sentence in skb && else if the freqency of word less then threshold:\n",
    "                    replace the word to sememe:\n",
    "                        if the sense of word only once:\n",
    "                            straightforward replace else more thinking... of (sense dismatching- now leave aside)\n",
    "                        else:\n",
    "                            search the sentence embedding of docs by look-up embedding dictionary\n",
    "                            for building the word embedding with weighted sum of sentence:\n",
    "                                senses cosin = list\n",
    "                                for index, sense the enumerate(senses):\n",
    "                                    word cosin = list\n",
    "                                    for sememe in sense:\n",
    "                                        compare both that the embedding of the word and the sememe of the sense\n",
    "                                        append the cosin value to word cosin list\n",
    "                                    keep minimum of senses cosin to append the senses cosin list\n",
    "                                get the index of minimum value for sense senses list\n",
    "                                get the word via index with this word senses of SKB-DA\n",
    "                            replace  \n",
    "        return: docs list replaced with sememe\n",
    "    '''\n",
    "    sememe_docs_list = []\n",
    "\n",
    "    '''\n",
    "        threshold = np.mean(list(docs_tuple[0].values())) + np.std(list(word_freq.values())) /\\\n",
    "                np.mean(list(word_freq.values()))\n",
    "    '''\n",
    "    threshold = threshold\n",
    "    ferquncy_max_word_list = [word for (word,_) in raw_word_freq_sorted[-round(ferquncy_max*len(docs_tuple[2])):]]\n",
    "    for sentence in tqdm.tqdm(docs_tuple[2]):\n",
    "        sentence_replace = []\n",
    "        for word in sentence.split():\n",
    "            #print(\"####\",word)\n",
    "            if word in skb_dict.keys() and (docs_tuple[0][word] < threshold or word in ferquncy_max_word_list):\n",
    "                if len(skb_dict[word]) == 1:\n",
    "                    sentence_replace += [\"<S\"+str(skb_cdv_map[sememe])+\">\" \\\n",
    "                                         for sememe in list(skb_dict[word][0][1])]\n",
    "                else:\n",
    "                    if word not in embedding_dict.keys():\n",
    "                        sentence_replace += [\"<S\"+str(skb_cdv_map[sememe])+\">\" \\\n",
    "                                             for sememe in list(skb_dict[word][0][1])]\n",
    "                    else:\n",
    "                        senses_cos_list = []\n",
    "                        for (_, sememe_set) in skb_dict[word]:\n",
    "                            senses_cos_list.append(localAttention(\\\n",
    "                                                sentence, word, list(sememe_set), embedding_dict)[0])\n",
    "                            #print(senses_cos_list)\n",
    "                        if len(senses_cos_list) == 0:\n",
    "                            sentence_replace.append(word)\n",
    "                            continue\n",
    "                        senses_cos_list_max_index = senses_cos_list.index(max(senses_cos_list))\n",
    "                        sentence_replace += [\"<S\"+str(skb_cdv_map[sememe])+\">\" \\\n",
    "                                             for sememe in list(skb_dict[word][senses_cos_list_max_index][1]) ]\n",
    "                        #sentence_replace += list(skb_dict[word][senses_cos_list_max_index][1])          \n",
    "            else:\n",
    "                sentence_replace.append(word)\n",
    "        sememe_docs_list.append(\" \".join(sentence_replace))\n",
    "    return sememe_docs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d2f4e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanBySKB(embedding_dict, skb_dict, doc_content_tuple, ferquncy_mix, skb_cdv_map, ferquncy_max):\n",
    "    sememe_docs_list = replaceWord2Sememe(embedding_dict,\\\n",
    "                                      skb_dict,\\\n",
    "                                      doc_content_tuple,\\\n",
    "                                      ferquncy_mix,skb_cdv_map,ferquncy_max)\n",
    "    clean_word_freq, clean_word_freq_sorted = evaluationFrequncy(sememe_docs_list,\"clran_ohsumed\",ferquncy_mix)\n",
    "    return (clean_word_freq, clean_word_freq_sorted,sememe_docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "15251f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _networkskbForm(networkskb):\n",
    "    '''uniform for NetWorkSKB'''\n",
    "    networkskb_form = {}\n",
    "    for wn_k,wn_v in networkskb.items():\n",
    "        word = wn_k.split(\".\")[0]\n",
    "        if word not in networkskb_form.keys():\n",
    "            networkskb_form[word] = []\n",
    "        networkskb_form[word].append((wn_k.split(\".\")[1],wn_v))\n",
    "    return networkskb_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ee56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a33f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "STC_Benchmark_path = \"../benchmark\"\n",
    "Ohsumed_training: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_training.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_test: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_test.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_category_description: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_category_description.npy\", allow_pickle=True).tolist()\n",
    "Ohsumed_ohsumed_all: dict = np.load(STC_Benchmark_path+\"/Ohsumed/Ohsumed_ohsumed_all.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4f5e6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "skb_da = np.load(\"../sememe_dataset/skb_ad_dict.npy\", allow_pickle=True).tolist()\n",
    "dictskb = np.load(\"../sememe_dataset/DictSKB_dict.npy\", allow_pickle=True).tolist()\n",
    "networkskb = np.load(\"../sememe_dataset/sememe_network_dict_en_wordnet_5000.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "181326ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 910369/910369 [01:27<00:00, 10408.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#all lexicon of SKB-DA: 800795; #CDV of SKB-DA: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 800795/800795 [00:02<00:00, 300464.46it/s]\n"
     ]
    }
   ],
   "source": [
    "skb_da_pure,skb_da_pure_cdv_set = removeWikiSenseOnSKBDA(skb_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1359334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skb_da_cdv_map = {word:index for index, word in enumerate(skb_da_pure_cdv_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a25e6959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196018it [01:11, 30561.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 2196017  words loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "glove_840B_300d_common_crawl = loadGloveModel(\"../data/embeddings/glove.840B.300d.common_crawl.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "41cf10b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 800795/800795 [00:33<00:00, 23651.10it/s]\n"
     ]
    }
   ],
   "source": [
    "skb_da_upper_max = upperMaxSKB(skb_da_pure,glove_840B_300d_common_crawl,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e170b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "networkskb = _networkskbForm(networkskb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "808ca7c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======analysis start=======\n",
      "#all word size:  11235\n",
      "#frequncy < 2:  5593\n",
      "#frequncy mean:  5.6333778371161545\n",
      "#frequncy standard deviation:  16.497707581203464\n",
      "#frequncy std/mean:  2.92856400870299\n"
     ]
    }
   ],
   "source": [
    "Ohsumed_list = [k for k,v in Ohsumed_test.items()] + [k for k,v in Ohsumed_training.items()]\n",
    "#Ohsumed_list = reuptext(Ohsumed_list)\n",
    "Ohsumed_list = [cleanText(cleanNonEnglish(sentence).strip()).strip() for sentence in Ohsumed_list]\n",
    "raw_word_freq, raw_word_freq_sorted = evaluationFrequncy(Ohsumed_list,\"raw_ohsumed\",limit_num=2)\n",
    "doc_content_tuple = (raw_word_freq,raw_word_freq_sorted,Ohsumed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c690007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8d7580cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 7400/7400 [02:47<00:00, 44.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======analysis start=======\n",
      "#all word size:  7584\n",
      "#frequncy < 100:  7152\n",
      "#frequncy mean:  21.660996835443036\n",
      "#frequncy standard deviation:  69.72626880187721\n",
      "#frequncy std/mean:  3.2189778398280757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc_content_tuple = cleanBySKB(glove_840B_300d_common_crawl,\\\n",
    "                               skb_da_upper_max,doc_content_tuple,100,skb_da_cdv_map,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1794f174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 7400/7400 [00:00<00:00, 130365.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======analysis start=======\n",
      "#all word size:  17747\n",
      "#frequncy < 5:  13299\n",
      "#frequncy mean:  5.214120696455739\n",
      "#frequncy standard deviation:  13.69576692790837\n",
      "#frequncy std/mean:  2.6266685650790493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc_content_tuple = cleanBySKB(glove_840B_300d_common_crawl,skb_da_pure,doc_content_tuple,5,skb_da_cdv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5cbbb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skb_Ohsumed = doc_content_tuple[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd615c3",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2a6ca556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3d21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======analysis start=======\n",
      "#all word size:  154234\n",
      "#frequncy < 5:  114539\n",
      "#frequncy mean:  19.57630613224062\n",
      "#frequncy standard deviation:  247.79825654870734\n",
      "#frequncy std/mean:  12.658070162715902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                                  | 142/18846 [00:20<16:38, 18.73it/s]"
     ]
    }
   ],
   "source": [
    "newsgroups_list = newsgroups_train.data + newsgroups_test.data\n",
    "newsgroups_list = [cleanText(cleanNonEnglish(sentence).strip()).strip() for sentence in newsgroups_list]\n",
    "raw_word_freq, raw_word_freq_sorted = evaluationFrequncy(newsgroups_list,\"raw_ohsumed\",limit_num=5)\n",
    "doc_content_tuple = (raw_word_freq,raw_word_freq_sorted,newsgroups_list)\n",
    "newsgroups = cleanBySKB(glove_840B_300d_common_crawl,\\\n",
    "                               skb_da_upper_max,doc_content_tuple,5,skb_da_cdv_map,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9ac00cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = reuptext(list(Ohsumed_training.keys()))\n",
    "X_test = reuptext(list(Ohsumed_test.keys()))\n",
    "y_train = [v[0] for v in list(Ohsumed_training.values())]\n",
    "y_test = [v[0] for v in list(Ohsumed_test.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c17c32d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C01       1.00      0.02      0.04       102\n",
      "         C02       0.00      0.00      0.00        50\n",
      "         C03       0.00      0.00      0.00        29\n",
      "         C04       0.45      0.82      0.58       600\n",
      "         C05       0.00      0.00      0.00       140\n",
      "         C06       0.82      0.05      0.10       178\n",
      "         C07       0.00      0.00      0.00        34\n",
      "         C08       0.00      0.00      0.00       129\n",
      "         C09       0.00      0.00      0.00        28\n",
      "         C10       0.88      0.04      0.08       342\n",
      "         C11       0.00      0.00      0.00        76\n",
      "         C12       1.00      0.01      0.02       187\n",
      "         C13       0.50      0.01      0.02       103\n",
      "         C14       0.23      0.98      0.37       590\n",
      "         C15       0.00      0.00      0.00        79\n",
      "         C16       0.00      0.00      0.00        70\n",
      "         C17       1.00      0.02      0.03       132\n",
      "         C18       0.96      0.17      0.30       155\n",
      "         C19       0.00      0.00      0.00        46\n",
      "         C20       0.75      0.19      0.31       231\n",
      "         C21       0.85      0.23      0.36       313\n",
      "         C22       0.00      0.00      0.00        10\n",
      "         C23       0.32      0.16      0.21       419\n",
      "\n",
      "    accuracy                           0.32      4043\n",
      "   macro avg       0.38      0.12      0.10      4043\n",
      "weighted avg       0.51      0.32      0.23      4043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                     ])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "37435a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = skb_Ohsumed[len(Ohsumed_test):]\n",
    "X_test = skb_Ohsumed[:len(Ohsumed_test)]\n",
    "y_train = [v[0] for v in list(Ohsumed_training.values())]\n",
    "y_test = [v[0] for v in list(Ohsumed_test.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8dfc9629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C01       0.80      0.04      0.07       102\n",
      "         C02       0.00      0.00      0.00        50\n",
      "         C03       0.00      0.00      0.00        29\n",
      "         C04       0.41      0.81      0.54       600\n",
      "         C05       0.00      0.00      0.00       140\n",
      "         C06       0.91      0.06      0.11       178\n",
      "         C07       0.00      0.00      0.00        34\n",
      "         C08       0.00      0.00      0.00       129\n",
      "         C09       0.00      0.00      0.00        28\n",
      "         C10       0.80      0.04      0.07       342\n",
      "         C11       0.00      0.00      0.00        76\n",
      "         C12       0.50      0.01      0.01       187\n",
      "         C13       0.60      0.03      0.06       103\n",
      "         C14       0.24      0.99      0.38       590\n",
      "         C15       0.00      0.00      0.00        79\n",
      "         C16       0.00      0.00      0.00        70\n",
      "         C17       1.00      0.02      0.03       132\n",
      "         C18       0.85      0.14      0.24       155\n",
      "         C19       0.00      0.00      0.00        46\n",
      "         C20       0.62      0.08      0.14       231\n",
      "         C21       0.76      0.17      0.28       313\n",
      "         C22       0.00      0.00      0.00        10\n",
      "         C23       0.19      0.10      0.13       419\n",
      "\n",
      "    accuracy                           0.31      4043\n",
      "   macro avg       0.33      0.11      0.09      4043\n",
      "weighted avg       0.44      0.31      0.20      4043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                     ])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1497534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9aebc94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C01       0.83      0.10      0.18       102\n",
      "         C02       0.00      0.00      0.00        50\n",
      "         C03       0.00      0.00      0.00        29\n",
      "         C04       0.43      0.87      0.58       600\n",
      "         C05       0.00      0.00      0.00       140\n",
      "         C06       1.00      0.12      0.21       178\n",
      "         C07       0.00      0.00      0.00        34\n",
      "         C08       1.00      0.01      0.02       129\n",
      "         C09       0.00      0.00      0.00        28\n",
      "         C10       0.76      0.05      0.09       342\n",
      "         C11       0.00      0.00      0.00        76\n",
      "         C12       0.83      0.03      0.05       187\n",
      "         C13       1.00      0.01      0.02       103\n",
      "         C14       0.25      0.99      0.40       590\n",
      "         C15       0.00      0.00      0.00        79\n",
      "         C16       0.00      0.00      0.00        70\n",
      "         C17       1.00      0.02      0.03       132\n",
      "         C18       0.97      0.19      0.32       155\n",
      "         C19       0.00      0.00      0.00        46\n",
      "         C20       0.69      0.12      0.20       231\n",
      "         C21       0.79      0.20      0.32       313\n",
      "         C22       0.00      0.00      0.00        10\n",
      "         C23       0.24      0.17      0.20       419\n",
      "\n",
      "    accuracy                           0.33      4043\n",
      "   macro avg       0.43      0.12      0.11      4043\n",
      "weighted avg       0.52      0.33      0.24      4043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "skb_Ohsumed: list = np.load(\"./cleandocs_stc_sl4_f10_once.npy\", allow_pickle=True).tolist()\n",
    "X_train = skb_Ohsumed[len(Ohsumed_test):]\n",
    "X_test = skb_Ohsumed[:len(Ohsumed_test)]\n",
    "y_train = [v[0] for v in list(Ohsumed_training.values())]\n",
    "y_test = [v[0] for v in list(Ohsumed_test.values())]\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                     ])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b61719c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C01       0.24      0.47      0.32       102\n",
      "         C02       0.30      0.20      0.24        50\n",
      "         C03       0.54      0.45      0.49        29\n",
      "         C04       0.46      0.77      0.58       600\n",
      "         C05       0.39      0.32      0.35       140\n",
      "         C06       0.40      0.54      0.46       178\n",
      "         C07       0.33      0.15      0.20        34\n",
      "         C08       0.35      0.36      0.35       129\n",
      "         C09       0.50      0.32      0.39        28\n",
      "         C10       0.57      0.44      0.49       342\n",
      "         C11       0.75      0.28      0.40        76\n",
      "         C12       0.51      0.37      0.43       187\n",
      "         C13       0.65      0.36      0.46       103\n",
      "         C14       0.55      0.77      0.64       590\n",
      "         C15       0.48      0.28      0.35        79\n",
      "         C16       0.54      0.29      0.37        70\n",
      "         C17       0.68      0.51      0.58       132\n",
      "         C18       0.55      0.42      0.48       155\n",
      "         C19       0.73      0.24      0.36        46\n",
      "         C20       0.55      0.48      0.51       231\n",
      "         C21       0.64      0.47      0.54       313\n",
      "         C22       0.00      0.00      0.00        10\n",
      "         C23       0.33      0.18      0.23       419\n",
      "\n",
      "    accuracy                           0.49      4043\n",
      "   macro avg       0.48      0.38      0.40      4043\n",
      "weighted avg       0.50      0.49      0.47      4043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "X_train = reuptext(list(Ohsumed_training.keys()))\n",
    "X_test = reuptext(list(Ohsumed_test.keys()))\n",
    "y_train = [v[0] for v in list(Ohsumed_training.values())]\n",
    "y_test = [v[0] for v in list(Ohsumed_test.values())]\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ccbf4fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C01       0.23      0.51      0.32       102\n",
      "         C02       0.33      0.28      0.30        50\n",
      "         C03       0.46      0.38      0.42        29\n",
      "         C04       0.46      0.73      0.57       600\n",
      "         C05       0.36      0.31      0.33       140\n",
      "         C06       0.29      0.51      0.37       178\n",
      "         C07       0.32      0.18      0.23        34\n",
      "         C08       0.31      0.31      0.31       129\n",
      "         C09       0.35      0.25      0.29        28\n",
      "         C10       0.51      0.37      0.43       342\n",
      "         C11       0.68      0.30      0.42        76\n",
      "         C12       0.52      0.35      0.42       187\n",
      "         C13       0.48      0.31      0.38       103\n",
      "         C14       0.53      0.71      0.60       590\n",
      "         C15       0.40      0.20      0.27        79\n",
      "         C16       0.50      0.20      0.29        70\n",
      "         C17       0.69      0.43      0.53       132\n",
      "         C18       0.50      0.42      0.46       155\n",
      "         C19       0.60      0.33      0.42        46\n",
      "         C20       0.53      0.40      0.46       231\n",
      "         C21       0.59      0.41      0.48       313\n",
      "         C22       0.00      0.00      0.00        10\n",
      "         C23       0.32      0.19      0.24       419\n",
      "\n",
      "    accuracy                           0.45      4043\n",
      "   macro avg       0.43      0.35      0.37      4043\n",
      "weighted avg       0.47      0.45      0.44      4043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train = skb_Ohsumed[len(Ohsumed_test):]\n",
    "X_test = skb_Ohsumed[:len(Ohsumed_test)]\n",
    "y_train = [v[0] for v in list(Ohsumed_training.values())]\n",
    "y_test = [v[0] for v in list(Ohsumed_test.values())]\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d5231a",
   "metadata": {},
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d93e047d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C01       0.61      0.50      0.55       102\n",
      "         C02       0.60      0.18      0.28        50\n",
      "         C03       0.83      0.52      0.64        29\n",
      "         C04       0.68      0.79      0.73       600\n",
      "         C05       0.66      0.43      0.52       140\n",
      "         C06       0.55      0.64      0.59       178\n",
      "         C07       0.80      0.24      0.36        34\n",
      "         C08       0.62      0.55      0.58       129\n",
      "         C09       0.56      0.36      0.43        28\n",
      "         C10       0.64      0.54      0.59       342\n",
      "         C11       0.71      0.36      0.47        76\n",
      "         C12       0.68      0.55      0.61       187\n",
      "         C13       0.65      0.50      0.57       103\n",
      "         C14       0.64      0.85      0.73       590\n",
      "         C15       0.65      0.42      0.51        79\n",
      "         C16       0.51      0.31      0.39        70\n",
      "         C17       0.67      0.62      0.65       132\n",
      "         C18       0.61      0.65      0.62       155\n",
      "         C19       0.53      0.17      0.26        46\n",
      "         C20       0.63      0.68      0.65       231\n",
      "         C21       0.63      0.67      0.65       313\n",
      "         C22       0.50      0.10      0.17        10\n",
      "         C23       0.33      0.36      0.34       419\n",
      "\n",
      "    accuracy                           0.61      4043\n",
      "   macro avg       0.62      0.48      0.52      4043\n",
      "weighted avg       0.61      0.61      0.60      4043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "X_train = reuptext(list(Ohsumed_training.keys()))\n",
    "X_test = reuptext(list(Ohsumed_test.keys()))\n",
    "y_train = [v[0] for v in list(Ohsumed_training.values())]\n",
    "y_test = [v[0] for v in list(Ohsumed_test.values())]\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "59a4f583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C01       0.51      0.58      0.54       102\n",
      "         C02       0.57      0.24      0.34        50\n",
      "         C03       0.94      0.52      0.67        29\n",
      "         C04       0.69      0.80      0.74       600\n",
      "         C05       0.59      0.39      0.47       140\n",
      "         C06       0.56      0.60      0.58       178\n",
      "         C07       0.64      0.21      0.31        34\n",
      "         C08       0.57      0.53      0.55       129\n",
      "         C09       0.56      0.36      0.43        28\n",
      "         C10       0.58      0.49      0.53       342\n",
      "         C11       0.78      0.46      0.58        76\n",
      "         C12       0.77      0.55      0.64       187\n",
      "         C13       0.67      0.45      0.53       103\n",
      "         C14       0.66      0.82      0.73       590\n",
      "         C15       0.66      0.39      0.49        79\n",
      "         C16       0.47      0.30      0.37        70\n",
      "         C17       0.68      0.59      0.63       132\n",
      "         C18       0.60      0.66      0.63       155\n",
      "         C19       0.61      0.30      0.41        46\n",
      "         C20       0.59      0.63      0.61       231\n",
      "         C21       0.56      0.63      0.59       313\n",
      "         C22       0.00      0.00      0.00        10\n",
      "         C23       0.31      0.36      0.33       419\n",
      "\n",
      "    accuracy                           0.59      4043\n",
      "   macro avg       0.59      0.47      0.51      4043\n",
      "weighted avg       0.59      0.59      0.58      4043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/adaptsystemlab2019/yes/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train = skb_Ohsumed[len(Ohsumed_test):]\n",
    "X_test = skb_Ohsumed[:len(Ohsumed_test)]\n",
    "y_train = [v[0] for v in list(Ohsumed_training.values())]\n",
    "y_test = [v[0] for v in list(Ohsumed_test.values())]\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0ea33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
